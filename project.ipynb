{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Motivation\n",
        "\n",
        "In neural network models like GPT-2, understanding the role and influence of individual neurons can provide insights into how these models process and generate language. Identifying the most influential neurons could lead to more efficient and interpretable models.\n",
        "\n",
        "Despite GPT-2's success in various natural language processing tasks, its robustness and worst-case behaviors remain less explored. This study aims to shed light on these aspects by comparing its performance and neuron influence with other models.\n",
        "\n",
        "The focus on pre-trained models, without fine-tuning, is to understand the inherent capabilities and biases these models have acquired during their initial training phase. This approach helps in evaluating the models' generalizability and adaptability to various tasks straight out-of-the-box.\n",
        "\n",
        "By including models such as <b>openlm-research/open_llama_3b_v2</b>, <b>EleutherAI/gpt-neo-2.7B</b>, and <b>ahxt/llama2_xs_460M_experimental</b>, which might have different architectural designs or training methodologies, the study aims to explore a diverse range of AI capabilities. This comparison could reveal unique strengths and weaknesses across different model architectures."
      ],
      "metadata": {
        "id": "bmGX5oN-VHQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approach\n",
        "\n",
        "**Model Selection**\n",
        "\n",
        "The study selects GPT-2 and compares it with other pre-trained models such as <b>openlm-research/open_llama_3b_v2</b>, <b>EleutherAI/gpt-neo-2.7B</b>, and <b>ahxt/llama2_xs_460M_experimental</b>. The selection criteria include model architecture, size, training data, and known performance metrics.\n",
        "\n",
        "**Neuron Analysis Method**\n",
        "\n",
        "Employing techniques to analyze the influence of individual neurons in each model. This might involve probing neurons for specific linguistic or cognitive tasks, or observing changes in model outputs when neurons are ablated or activated.\n",
        "\n",
        "**Comparative Analysis**\n",
        "\n",
        "The methodology includes direct comparisons between models based on the influence of their neurons. This could involve quantitative measures (e.g., changes in output probability distributions) or qualitative analyses (e.g., linguistic patterns captured by influential neurons).\n",
        "\n",
        "**Robustness and Behavior Assessment**\n",
        "\n",
        "Evaluating the models' performance in edge cases or under adversarial conditions. This helps in understanding the models' limits and how they react to unusual or unexpected inputs.\n",
        "\n",
        "**No Fine-Tuning Approach**\n",
        "\n",
        "Consistently, all models are used in their pre-trained state without any additional fine-tuning. This ensures that the comparison focuses on the inherent qualities of the models as they were originally trained."
      ],
      "metadata": {
        "id": "h8TjOHaoVNTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data\n",
        "\n",
        "In our research, we employ the Stanford Sentiment Treebank (SST) dataset, a key resource for sentiment analysis in natural language processing. The SST is distinguished by its in-depth annotation of movie reviews from Rotten Tomatoes. Each review is broken down into smaller phrases, with each assigned a sentiment rating, ranging from very negative to very positive. This granularity allows for a detailed understanding of sentiment at both the phrase and sentence levels.\n",
        "\n",
        "The use of SST in our study is important for comparing the performance of models like GPT-2 and other models in sentiment analysis. It provides a standardized framework to assess how these models process and interpret varying emotional distinction in text. This dataset not only helps in evaluating the overall sentiment analysis capabilities of the models but also aids in our broader objective of understanding their behavior and identifying influential neurons within their architectures."
      ],
      "metadata": {
        "id": "ERFwYKh2VNbF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "LVwZTNtrVXES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimental Setup"
      ],
      "metadata": {
        "id": "bjqCH0gRVYVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results\n",
        "**GPT-2**\n",
        "\n",
        "**ahxt/llama2_xs_460M_experimental**\n",
        "\n",
        "**openlm-research/open_llama_3b_v2**\n",
        "\n",
        "**EleutherAI/gpt-neo-2.7B**"
      ],
      "metadata": {
        "id": "XTxgT67ZVa0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of the Results"
      ],
      "metadata": {
        "id": "mUplDRQ0Vdsv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Future Work"
      ],
      "metadata": {
        "id": "j4iDk6lvVfcK"
      }
    }
  ]
}